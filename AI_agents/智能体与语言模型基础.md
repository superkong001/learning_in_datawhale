参考：[hello-agents](https://github.com/datawhalechina/hello-agents/tree/main)

# 概念

在人工智能领域，智能体被定义为任何能够通过 **传感器（Sensors）** 感知其所处 **环境（Environment）** ，并 **自主（Autonomy）** 地通过 **执行器（Actuators）** 采取 **行动（Action）** 以达成特定目标的实体。

<div align="center">
  <img width="605" height="284" alt="image" src="https://github.com/user-attachments/assets/562e2ad9-128f-4a81-ba8a-7ef530fe4890" />
</div>

## 智能体演进

- **反射智能体（Simple Reflex Agent）** ：它们的决策核心由工程师明确设计的“条件-动作”规则构成。经典的自动恒温器便是如此：若传感器感知的室温高于设定值，则启动制冷系统。
- **基于模型的反射智能体（Model-Based Reflex Agent）** ：引入了“状态”。这类智能体拥有一个内部的世界模型（World Model），用于追踪和理解环境中那些无法被直接感知的方面。它试图回答：“世界现在是什么样子的？”。例如，一辆在隧道中行驶的自动驾驶汽车，即便摄像头暂时无法感知到前方的车辆，它的内部模型依然会维持对那辆车存在、速度和预估位置的判断。这个内部模型让智能体拥有了初级的“记忆”，使其决策不再仅仅依赖于瞬时感知，而是基于一个更连贯、更完整的世界状态理解。
- **基于目标的智能体（Goal-Based Agent）** ：增加了有明确的目标。与前两者不同，它的行为不再是被动地对环境做出反应，而是主动地、有预见性地选择能够导向某个特定未来状态的行动。这类智能体需要回答的问题是：“我应该做什么才能达成目标？”。经典的例子是 GPS 导航系统：你的目标是到达公司，智能体会基于地图数据（世界模型），通过搜索算法（如 A*算法）来规划（Planning）出一条最优路径。这类智能体的核心能力体现在了对未来的考量与规划上。
- **基于效用的智能体（Utility-Based Agent）** ：引入多个目标。它为每一个可能的世界状态都赋予一个效用值，这个值代表了满意度的高低。智能体的核心目标不再是简单地达成某个特定状态，而是最大化期望效用。它需要回答一个更复杂的问题：“哪种行为能为我带来最满意的结果？”。这种架构让智能体学会在相互冲突的目标之间进行权衡，使其决策更接近人类的理性选择。
- **学习型智能体（Learning Agent）** ： 不依赖于人类设计师的先验知识。它的核心思想是通过与环境的互动自主学习，而强化学习（Reinforcement Learning, RL）是实现这一思想最具代表性的路径。一个学习型智能体包含一个性能元件（即前面讨论的各类智能体）和一个学习元件。学习元件通过观察性能元件在环境中的行动所带来的结果来不断修正性能元件的决策策略。

### LLM智能体与传统智能体的区别

传统智能体的能力源于工程师的显式编程与知识构建，其行为模式是确定且有边界的；而 LLM 智能体则通过在海量数据上的预训练，获得了隐式的世界模型与强大的涌现能力，使其能够以更灵活、更通用的方式应对复杂任务。

<div align="center"> 
  <img width="627" height="173" alt="image" src="https://github.com/user-attachments/assets/b7fcaea0-293d-4ec0-bb0f-12cc77a1ebe9" />
</div>

以一个“智能旅行助手”为例执行流程：

- **规划与推理**：智能体首先会将这个高层级目标分解为一系列逻辑子任务，例如：[确认出行偏好] -> [查询目的地信息] -> [制定行程草案] -> [预订票务住宿]。这是一个内在的、由模型驱动的规划过程。
- **工具使用**：在执行规划时，智能体识别到信息缺口，会主动调用外部工具来补全。例如，它会调用天气查询接口获取实时天气，并基于“预报有雨”这一信息，在后续规划中倾向于推荐室内活动。
- **动态修正**：在交互过程中，智能体会将用户的反馈（如“这家酒店超出预算”）视为新的约束，并据此调整后续的行动，重新搜索并推荐符合新要求的选项。整个“查天气 → 调行程 → 订酒店”的流程，展现了其根据上下文动态修正自身行为的能力。

## 智能体类型

- 基于内部决策架构的分类
- 基于时间与反应性的分类：反应式智能体 (Reactive Agents)、规划式智能体(Deliberative Agents)、混合式智能体(Hybrid Agents)

  经典的混合架构是分层设计：底层是一个快速的反应模块，处理紧急情况和基本动作；高层则是一个审慎的规划模块，负责制定长远目标，形成分解为一系列“规划-反应”的微循环。而现代的 LLM 智能体，则展现了一种更灵活的混合模式。它们通常在一个“思考-行动-观察”的循环中运作，巧妙地将两种模式融为一体：

  - 规划(Reasoning) ：在“思考”阶段，LLM 分析当前状况，规划出下一步的合理行动。这是一个审议过程。
  - 反应(Acting & Observing) ：在“行动”和“观察”阶段，智能体与外部工具或环境交互，并立即获得反馈。这是一个反应过程。
    
- 基于知识表示的分类
  - 符号主义 AI（Symbolic AI）：智能源于对符号的逻辑操作。这里的符号是人类可读的实体（如词语、概念），操作则遵循严格的逻辑规则。其主要优势在于透明和可解释。
  - 亚符号主义 AI（Sub-symbolic AI）：知识并非显式的规则，而是内隐地分布在一个由大量神经元组成的复杂网络中，是从海量数据中学习到的统计模式。神经网络和深度学习是其代表。
  - 神经符号主义 AI（Neuro-Symbolic AI）：融合两大范式的优点，创造出一个既能像神经网络一样从数据中学习，又能像符号系统一样进行逻辑推理的混合智能体。它试图弥合感知与认知、直觉与理性之间的鸿沟。诺贝尔经济学奖得主丹尼尔·卡尼曼（Daniel Kahneman）在其著作《思考，快与慢》（Thinking, Fast and Slow）中提出的双系统理论。
    - 系统 1是快速、凭直觉、并行的思维模式，类似于亚符号主义 AI 强大的模式识别能力。
    - 系统 2是缓慢、有条理、基于逻辑的审慎思维，恰如符号主义 AI 的推理过程。

<div align="center">  
      <img width="579" height="227" alt="image" src="https://github.com/user-attachments/assets/f9ee63b6-e28f-417c-8321-1a1336881127" />
</div>

## 智能体的构成与运行原理

### 任务环境定义

通常使用 **PEAS 模型** 来精确描述一个任务环境，即 **分析其性能度量(Performance)、环境(Environment)、执行器(Actuators)和传感器(Sensors)** 。

<div align="center">  
  <img width="617" height="139" alt="image" src="https://github.com/user-attachments/assets/3815df48-efa8-4ff7-8904-797573326817" />
</div>

### 智能体的运行机制

<div align="center">  
  <img width="632" height="214" alt="image" src="https://github.com/user-attachments/assets/4eeb0f5c-0603-48f8-9d53-86f080651205" />
</div>

循环主要包含以下几个相互关联的阶段：

1. 感知 (Perception)：这是循环的起点。智能体通过其传感器（例如，API 的监听端口、用户输入接口）接收来自环境的输入信息。这些信息，即观察 (Observation)，既可以是用户的初始指令，也可以是上一步行动所导致的环境状态变化反馈。
2. 思考 (Thought)：接收到观察信息后，智能体进入其核心决策阶段。对于 LLM 智能体而言，这通常是由大语言模型驱动的内部推理过程。如图所示，“思考”阶段可进一步细分为两个关键环节：
   - 规划 (Planning)：智能体基于当前的观察和其内部记忆，更新对任务和环境的理解，并制定或调整一个行动计划。这可能涉及将复杂目标分解为一系列更具体的子任务。
   - 工具选择 (Tool Selection)：根据当前计划，智能体从其可用的工具库中，选择最适合执行下一步骤的工具，并确定调用该工具所需的具体参数。
3. 行动 (Action)：决策完成后，智能体通过其执行器（Actuators）执行具体的行动。这通常表现为调用一个选定的工具（如代码解释器、搜索引擎 API），从而对环境施加影响，意图改变环境的状态。

由 **Thought-Action-Observation** 构成循环的交互范式：
-  Thought (思考)：这是智能体内部决策的“快照”。它以自然语言形式阐述了智能体如何分析当前情境、回顾上一步的观察结果、进行自我反思与问题分解，并最终规划出下一步的具体行动。
-  Action (行动)：这是智能体基于思考后，决定对环境施加的具体操作，通常以函数调用的形式表示。
-  Observation：扮演传感器的角色，将行动执行后环境会返回原始结果输出处理并封装成一段简洁、清晰的自然语言文本，即观察。

## 智能体应用的协作模式

- 作为开发者工具的智能体：智能体被深度集成到开发者的工作流中，作为一种强大的辅助工具。它增强而非取代开发者的角色，通过自动化处理繁琐、重复的任务，让开发者能更专注于创造性的核心工作。如：GitHubCopilot、Claude Code、Trae、Cursor。
- 作为自主协作者的智能体：智能体会像一个真正的项目成员一样，独立地进行规划、推理、执行和反思，直到最终交付成果。这种从助手到协作者的转变，使得 LLM 智能体更深的进入了大众的视野。它标志着我们与 AI 的关系从“命令-执行”演变为“目标-委托”。智能体不再是被动的工具，而是主动的目标追求者。有 CrewAI、AutoGen、MetaGPT、LangGraph 等优秀自主协作框架。

  1. 单智能体自主循环：这是早期的典型范式，如 AgentGPT 所代表的模式。其核心是一个通用智能体通过“思考-规划-执行-反思”的闭环，不断进行自我提示和迭代，以完成一个开放式的高层级目标。
  2. 多智能体协作：这是当前最主流的探索方向，旨在通过模拟人类团队的协作模式来解决复杂问题。它又可细分为不同模式： 角色扮演式对话：如 CAMEL 框架，通过为两个智能体（例如，“程序员”和“产品经理”）设定明确的角色和沟通协议，让它们在一个结构化的对话中协同完成任务。 组织化工作流：如 MetaGPT 和 CrewAI，它们模拟一个分工明确的“虚拟团队”（如软件公司或咨询小组）。每个智能体都有预设的职责和工作流程（SOP），通过层级化或顺序化的方式协作，产出高质量的复杂成果（如完整的代码库或研究报告）。AutoGen 和 AgentScope 则提供了更灵活的对话模式，允许开发者自定义智能体间的复杂交互网络。
  3. 高级控制流架构：诸如 LangGraph 等框架，则更侧重于为智能体提供更强大的底层工程基础。它将智能体的执行过程建模为状态图（State Graph），从而能更灵活、更可靠地实现循环、分支、回溯以及人工介入等复杂流程。
 
## Workflow 和 Agent 的差异

**Workflow 是让 AI 按部就班地执行指令（对一系列任务或步骤进行预先定义的、结构化的编排），而 Agent 则是赋予 AI 自由度去自主达成目标（具备自主性的、以目标为导向的系统，能够在一定程度上理解环境、进行推理、制定计划，并动态地采取行动以达成最终目标。）。**

<img width="631" height="449" alt="image" src="https://github.com/user-attachments/assets/f243a3e1-ca9e-443f-8d93-a265b359eb81" />




